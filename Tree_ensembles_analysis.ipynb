{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "according-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "administrative-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "competent-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_tree as pipeline_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "incomplete-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['province','age','education', 'if_urban',\n",
    "                 'wealth_index', 'if_own_house',\n",
    "                 'if_employment', 'if_employment_current','employment_pay_method', 'if_earn_more',\n",
    "                 'partner_edu', \n",
    "                 'num_child','sex_head_household', 'sexual_activity', 'ideal_num_child', 'partner_ideal_child', 'money_decide_person']\n",
    "NUMERIC_FEATURES = ['age','education','if_own_house','if_employment_current','partner_edu','num_child','ideal_num_child']\n",
    "CATGORICAL_FEATURES = ['province', 'if_urban',\n",
    "                 'wealth_index',\n",
    "                 'if_employment','employment_pay_method','if_earn_more', \n",
    "                 'sex_head_household', 'sexual_activity', 'partner_ideal_child', 'money_decide_person']\n",
    "TARGET_LST = ['if_emo_vio', 'if_phy_vio', 'if_sex_vio', 'if_vio', 'num_vio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "sought-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = ['cleaned_data/cambodia_2014_cleaned.csv', \n",
    "         'cleaned_data/Maldives_2016_cleaned.csv', \n",
    "         'cleaned_data/Nepal_2016_cleaned.csv',\n",
    "         'cleaned_data/Pakistan_2017_cleaned.csv',\n",
    "         'cleaned_data/Philippines_2017_cleaned.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-moldova",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "pending-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    target, \n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=505)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "seeing-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, features_col, target_col, categorical_col):\n",
    "    df.dropna(subset=[target_col],inplace=True)\n",
    "    df = impute_missing_median(df, NUMERIC_FEATURES)\n",
    "    df = fill_categorical_na_vals(df)\n",
    "    features = df[features_col]\n",
    "    features = pd.get_dummies(features, columns=categorical_col)\n",
    "    target = df[target_col]\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ancient-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_median(df, col_lst):\n",
    "    '''\n",
    "    Impute missing values of continuous variables using the median value\n",
    "    '''\n",
    "    for col in col_lst:\n",
    "        df.loc[(df[col] == \"don't know\") | (df[col] == \"non-numeric response\") , col] = None\n",
    "        median = df[col].median()\n",
    "        df[col].fillna(median,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "written-toolbox",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_categorical_na_vals(df):\n",
    "    '''\n",
    "    Find colums and rows with missing values. Print rows, returns list of\n",
    "    columns.\n",
    "    '''\n",
    "    df = df.fillna(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "static-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train, X_test, y_train, y_test):\n",
    "    params = {'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [3,5,10,20],\n",
    "                'min_samples_split': [2,5,10]}\n",
    "    grid_model = GridSearchCV(estimator=DecisionTreeClassifier(random_state=505), \n",
    "                              param_grid=params, \n",
    "                              cv=10,\n",
    "                              return_train_score=True,\n",
    "                              scoring=['f1', 'accuracy','precision','recall','roc_auc'],\n",
    "                              refit='f1')\n",
    "\n",
    "    grid_model.fit(X_train, y_train)\n",
    "\n",
    "    grid_result = pd.DataFrame(grid_model.cv_results_)\n",
    "    grid_result[['params','mean_train_f1','mean_train_accuracy', 'mean_train_precision','mean_train_recall','mean_train_roc_auc']]\n",
    "    grid_result.sort_values(by=['mean_train_f1'], ascending=False)\n",
    "    pd.set_option('max_colwidth',500)\n",
    "#     print('Best model params: ', grid_result.loc[grid_result['mean_train_accuracy'] == max(grid_result['mean_train_accuracy'])]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "hundred-henry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, X_test, y_train, y_test):\n",
    "    params = {'n_estimators':[100, 1000],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "              'max_depth': [3,5,10,20],\n",
    "              'min_samples_split': [2,5,10]}\n",
    "    grid_model = GridSearchCV(estimator=RandomForestClassifier(random_state=505), \n",
    "                              param_grid=params, \n",
    "                              cv=10,\n",
    "                              return_train_score=True,\n",
    "                              scoring=['f1', 'accuracy','precision','recall','roc_auc'],\n",
    "                              refit='f1')\n",
    "\n",
    "    grid_model.fit(X_train, y_train)\n",
    "\n",
    "    grid_result = pd.DataFrame(grid_model.cv_results_)\n",
    "    grid_result[['params','mean_train_f1','mean_train_accuracy', 'mean_train_precision','mean_train_recall','mean_train_roc_auc']]\n",
    "    grid_result.sort_values(by=['mean_train_f1'], ascending=False)\n",
    "    pd.set_option('max_colwidth',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "appreciated-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    plot_precision_recall_curve(model, X_test, y_test)\n",
    "    results_dict = {}\n",
    "    results_dict['f1'] = metrics.f1_score(y_test, y_pred)\n",
    "    results_dict['accuracy'] = metrics.accuracy_score(y_test, y_pred)\n",
    "    results_dict['precision'] = metrics.precision_score(y_test, y_pred)\n",
    "    results_dict['recall'] = metrics.recall_score(y_test, y_pred)\n",
    "    results_dict['roc_auc'] = metrics.roc_auc_score(y_test, y_pred)\n",
    "    plot_precision_recall_curve(model,X_test,y_test)\n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "affecting-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importances(model, n=5, title=''):\n",
    "    '''\n",
    "    Compute the relative importance of selected features in\n",
    "    the model\n",
    "    \n",
    "    Inputs:\n",
    "    - model\n",
    "    - n (int): top n features, opt\n",
    "    - title (str)\n",
    "    '''\n",
    "    importances = model.feature_importances_\n",
    "    np_features = np.array(features)\n",
    "    sorted_idx = np.argsort(importances)[len(np_features)-n:]\n",
    "    padding = np.arange(len(sorted_idx)) + 0.5\n",
    "    pl.barh(padding, importances[sorted_idx], align='center')\n",
    "    pl.yticks(padding, np_features[sorted_idx])\n",
    "    pl.xlabel(\"Relative Importance\")\n",
    "    pl.title(title)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "entertaining-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(csv):\n",
    "    return pd.read_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "intensive-authorization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alternative-custom",
   "metadata": {},
   "source": [
    "# Cambodia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "guided-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data('cleaned_data/cambodia_2014_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "wicked-field",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Target:  if_emo_vio\n",
      "\n",
      " Target:  if_phy_vio\n",
      "\n",
      " Target:  if_sex_vio\n",
      "\n",
      " Target:  if_vio\n",
      "\n",
      " Target:  num_vio\n"
     ]
    }
   ],
   "source": [
    "for target_col in TARGET_LST:\n",
    "    print(\"\\n Target: \", target_col)\n",
    "    features, target = preprocess_data(df, FEATURES, target_col, CATGORICAL_FEATURES)\n",
    "    X_train, X_test, y_train, y_test = split_data(features, target)\n",
    "    train_decision_tree(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-outside",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-spider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-monitoring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importances(df, features, label, n=10, title=''):\n",
    "    '''\n",
    "    Build a random forest classifier to\n",
    "    compute the relative importance of selected features in\n",
    "    predicting the label.\n",
    "    \n",
    "    Inputs:\n",
    "    - df (pd.DataFrame)\n",
    "    - features (lst of str)\n",
    "    - label (str)\n",
    "    - n (int): top n features, opt\n",
    "    - title (str)\n",
    "    '''\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(df[features], df[label])\n",
    "    importances = clf.feature_importances_\n",
    "    np_features = np.array(features)\n",
    "    sorted_idx = np.argsort(importances)[len(np_features)-n:]\n",
    "    padding = np.arange(len(sorted_idx)) + 0.5\n",
    "    pl.barh(padding, importances[sorted_idx], align='center')\n",
    "    pl.yticks(padding, np_features[sorted_idx])\n",
    "    pl.xlabel(\"Relative Importance\")\n",
    "    pl.title(title)\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-glossary",
   "metadata": {},
   "source": [
    "[Reference: Decision Tree Ensembles- Bagging and Boosting](https://towardsdatascience.com/decision-tree-ensembles-bagging-and-boosting-266a8ba60fd9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
